{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b82aa261-6948-4a67-b308-f20783f63cc1",
   "metadata": {},
   "source": [
    "              -----------WEEK 2 - Day 1-----------\n",
    "                                - Manojkiran G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff577e-e943-4034-814a-9ce5f673e563",
   "metadata": {},
   "source": [
    "## Pandas Continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0af3b57f-c302-4127-94cb-4e2a950d3d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397cc620-4755-42d2-9181-d60ec4fbf4fe",
   "metadata": {},
   "source": [
    "### Grouping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5952f92b-269f-44f2-9950-b4809929bb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sample data \n",
    "data = {'Category': ['Electronics', 'Clothing', 'Electronics', 'Clothing', 'Electronics', 'Clothing'],\n",
    "        'Gender': ['Male', 'Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "        'Sales': [1200, 800, 1000, 900, 1500, 1100],\n",
    "        'Discounts': [50, 20, 30, 40, 10, 15],\n",
    "        'Profit': [200, 100, 150, 120, 250, 180]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3bcf99-a2ac-40ac-9c39-7213c6dff0a2",
   "metadata": {},
   "source": [
    "#### Group with a single column using groupby method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82728ec0-b2e7-4956-99dd-7409a6f03004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Female    3000\n",
      "Male      3500\n",
      "Name: Sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Grouping by 'Gender'\n",
    "grouped_sales = df.groupby('Gender')\n",
    "\n",
    "# Calculating total sales for each gender\n",
    "total_sales_by_gender = grouped_sales['Sales'].sum()\n",
    "\n",
    "print(total_sales_by_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2528021-a0da-4135-9690-0bc128f15aba",
   "metadata": {},
   "source": [
    "#### Group with single column and apply to entire Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00090b15-be6b-40fc-9540-3ab0bc001770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Sales  Discounts  Profit\n",
      "Gender                          \n",
      "Female   3000         85     450\n",
      "Male     3500         80     550\n"
     ]
    }
   ],
   "source": [
    "# Grouping by 'Gender'\n",
    "grouped_sales = df.groupby('Gender')\n",
    "\n",
    "# Calculating total sales, total discounts, and total profit for each gender\n",
    "summary_by_gender = grouped_sales.agg({'Sales': 'sum', 'Discounts': 'sum', 'Profit': 'sum'})\n",
    "\n",
    "print(summary_by_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9678c9-bee4-4d54-b330-3172971f0b57",
   "metadata": {},
   "source": [
    "#### Group with multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2331e99-eb51-470f-9707-cd68416db056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category     Gender\n",
      "Clothing     Female    1000.0\n",
      "             Male       800.0\n",
      "Electronics  Female    1000.0\n",
      "             Male      1350.0\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped_data = df.groupby(['Category', 'Gender'])\n",
    "\n",
    "# Calculate the mean for Math_score\n",
    "sales_results = grouped_data['Sales'].mean()\n",
    "\n",
    "print(sales_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c52aaf-128b-4d7b-8f27-12b6bfbe3557",
   "metadata": {},
   "source": [
    "### Aggregate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7c778-a2dd-4445-9f02-1258c24093b6",
   "metadata": {},
   "source": [
    "#### Applying multiple aggregate functions for selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a0fdc74-9b1e-4fbb-9f62-4064d1bae585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Sales             Discounts         Profit          \n",
      "                      mean   min   max      mean min max   mean  min  max\n",
      "Category    Gender                                                       \n",
      "Clothing    Female  1000.0   900  1100      27.5  15  40  150.0  120  180\n",
      "            Male     800.0   800   800      20.0  20  20  100.0  100  100\n",
      "Electronics Female  1000.0  1000  1000      30.0  30  30  150.0  150  150\n",
      "            Male    1350.0  1200  1500      30.0  10  50  225.0  200  250\n"
     ]
    }
   ],
   "source": [
    "# Applying aggregation functions to 'sales', 'discounts', 'profit'\n",
    "aggregated_data = grouped_data.agg({\n",
    "    'Sales': ['mean', 'min', 'max'],\n",
    "    'Discounts': ['mean', 'min', 'max'],\n",
    "    'Profit': ['mean', 'min', 'max']\n",
    "})\n",
    "\n",
    "print(aggregated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993d45c-4d7a-4e02-8b7b-97cdc44b2107",
   "metadata": {},
   "source": [
    "#### Applying multiple aggregate functions to the grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b70af72-dfc8-4007-b975-9487db5f0b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      mean   min   max\n",
      "Category    Gender                    \n",
      "Clothing    Female  1000.0   900  1100\n",
      "            Male     800.0   800   800\n",
      "Electronics Female  1000.0  1000  1000\n",
      "            Male    1350.0  1200  1500\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean, min, and max scores for sales\n",
    "agg_results = grouped_data.Sales.agg(['mean', 'min', 'max'])\n",
    "\n",
    "print(agg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8692dad-fa4b-464d-b57a-4f10c71fb5c2",
   "metadata": {},
   "source": [
    "### Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "352adeb5-39b6-4b42-a9ea-69d02741ed10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': ['Bangalore', 'Kochi', 'Chennai', 'Gurgaon', 'Noida']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6236cc0b-6b48-41a4-b078-a404d08789de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           A\n",
      "B           \n",
      "Bangalore  1\n",
      "Chennai    3\n",
      "Gurgaon    4\n",
      "Kochi      2\n",
      "Noida      5\n"
     ]
    }
   ],
   "source": [
    "pivot_table = df.pivot_table(values='A', index='B', aggfunc='mean')\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99efdc-a36d-47c8-ad01-30714351931b",
   "metadata": {},
   "source": [
    "### Cross-Tabulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32cb9685-c335-4c08-a55c-fe50a2905bad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B  Bangalore  Chennai  Gurgaon  Kochi  Noida\n",
      "A                                           \n",
      "1          1        0        0      0      0\n",
      "2          0        0        0      1      0\n",
      "3          0        1        0      0      0\n",
      "4          0        0        1      0      0\n",
      "5          0        0        0      0      1\n"
     ]
    }
   ],
   "source": [
    "cross_tab = pd.crosstab(df['A'], df['B'])\n",
    "print(cross_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02fede-caac-4c4a-99f7-6c06eda3b95b",
   "metadata": {},
   "source": [
    "### Data Handling in Time Series Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba75847-471d-4127-84b2-5b98e92cc7a1",
   "metadata": {},
   "source": [
    "#### DateTime Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32aba5d-a5eb-4966-bc23-5c1c04bee82e",
   "metadata": {},
   "source": [
    "- Utilizing the pd.to_datetime method empowers you to transform a series with datetime values into a pandas datetime series, enabling seamless analysis. \n",
    "- Extracting components such as year, month, day, and hours becomes easily achievable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b6d743a-46e5-440d-b583-886ba0cb8e09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             DateTime  Year  Month  Day  Hour\n",
      "0 2023-01-15 12:30:00  2023      1   15    12\n",
      "1 2023-02-28 18:20:00  2023      2   28    18\n",
      "2 2023-03-10 09:45:00  2023      3   10     9\n"
     ]
    }
   ],
   "source": [
    "#sample data \n",
    "data = {'DateTime': ['2023-01-15 12:30:00', '2023-02-28 18:20:00', '2023-03-10 09:45:00']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'DateTime' column to DateTime\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "# Extract year, month, day, and hour\n",
    "df['Year'] = df['DateTime'].dt.year\n",
    "df['Month'] = df['DateTime'].dt.month\n",
    "df['Day'] = df['DateTime'].dt.day\n",
    "df['Hour'] = df['DateTime'].dt.hour\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff8068-638c-46d1-86a2-2418c0cbf2dd",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "- Resampling, a crucial technique in time series analysis, involves altering the frequency of your data, allowing for aggregation or transformation from one time frequency to another. \n",
    "- Whether for aggregating high-frequency data to a lower frequency or interpolating irregularly sampled data to a regular frequency, resampling provides a versatile tool for analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d71da27f-dfa3-41c6-b053-519511611275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Before resampling:\n",
      "            Price\n",
      "Date             \n",
      "2023-01-01    100\n",
      "2023-01-02    105\n",
      "2023-01-03     98\n",
      "2023-02-01    110\n",
      "2023-02-02    108\n",
      "2023-02-03    112\n",
      "\n",
      "Data After resampling:\n",
      "            Price\n",
      "Date             \n",
      "2023-01-31  101.0\n",
      "2023-02-28  110.0\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame with daily stock prices\n",
    "data = {'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-02-01', '2023-02-02', '2023-02-03'],\n",
    "        'Price': [100, 105, 98, 110, 108, 112]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'Date' column to DateTime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Set 'Date' as the index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Resample the data to monthly frequency, taking the average price for each month\n",
    "monthly_prices = df.resample('M').mean()\n",
    "\n",
    "print(\"Data Before resampling:\")\n",
    "print(df)\n",
    "print(\"\\nData After resampling:\")\n",
    "print(monthly_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12950411-ad34-4fbd-bc73-7fa1b6372825",
   "metadata": {},
   "source": [
    "### Shifting\n",
    "\n",
    "- Shifting, also known as time lagging, plays a pivotal role in time series analysis by displacing data points forward or backward in time. \n",
    "- It facilitates tasks like calculating differences between current and past or future data points and creating time lags for analyzing how past values influence future outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6127d3b6-f57e-44cc-b1ce-0121685ddc09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Value\n",
      "8   9     97\n",
      "1   2     25\n",
      "5   6     55\n",
      "0   1     86\n",
      "7   8     16\n"
     ]
    }
   ],
   "source": [
    "data = {'ID': np.arange(1, 11), 'Value': np.random.randint(1, 100, 10)}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Randomly sample 5 rows from the DataFrame\n",
    "sampled_df = df.sample(n=5, random_state=42)\n",
    "\n",
    "print(sampled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b864015-3c94-440c-beb2-8e2fddf6de73",
   "metadata": {},
   "source": [
    "### Rolling statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a207a-7a0f-4ef1-859e-8532f0fc35fe",
   "metadata": {},
   "source": [
    "- Rolling statistics, a widely employed technique in time series analysis, entails applying a statistical function to a moving window of data points. \n",
    "- This method, often referred to as rolling calculations or rolling windows, helps smooth out noise in time series data, making underlying patterns more discernible.\n",
    "- Rolling statistics, characterized by a fixed window size and the application of specific functions within that window, enhance the analysis of time series data. \n",
    "- This approach, encompassing functions like mean, sum, or standard deviation, proves invaluable for detecting trends or patterns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5faf20c2-e705-4126-bc52-60eeffd6ae90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value  Rolling_Sum\n",
      "0      1          NaN\n",
      "1      2          3.0\n",
      "2      3          5.0\n",
      "3      4          7.0\n",
      "4      5          9.0\n",
      "5      6         11.0\n",
      "6      7         13.0\n",
      "7      8         15.0\n",
      "8      9         17.0\n",
      "9     10         19.0\n"
     ]
    }
   ],
   "source": [
    "data = {'Value': np.arange(1, 11)}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the rolling sum with a window size of 2\n",
    "rolling_sum = df['Value'].rolling(window=2).sum()\n",
    "\n",
    "# Combine the original DataFrame with the rolling sum\n",
    "result_df = pd.concat([df,rolling_sum.rename('Rolling_Sum')], axis=1)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdcb3b-022f-41f8-8862-d5a5d60a770e",
   "metadata": {},
   "source": [
    "### Handling Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c970ab-e8ac-4ac6-803b-0943b91d4d8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96203dc-6c1c-474c-87f6-e0f1128ed42e",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding using pd.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c5ff54f-a8de-41e6-be48-e31de305d3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class  class_A  class_B  class_C\n",
      "0     A        1        0        0\n",
      "1     B        0        1        0\n",
      "2     A        1        0        0\n",
      "3     C        0        0        1\n",
      "4     B        0        1        0\n"
     ]
    }
   ],
   "source": [
    "data = {'class': ['A', 'B', 'A', 'C', 'B']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply one-hot encoding using pd.get_dummies\n",
    "one_hot_encoded = pd.get_dummies(df['class'],prefix='class')\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded columns\n",
    "result_df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c26b5-d651-46f7-8689-9b3240796e56",
   "metadata": {},
   "source": [
    "#### Label Encoding using Category type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "285b2286-3de2-40f7-9e83-f75cda702e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  City_LabelEncoded\n",
      "0    Chennai                  1\n",
      "1  Hyderabad                  3\n",
      "2  Bangalore                  0\n",
      "3      Delhi                  2\n",
      "4      Noida                  4\n"
     ]
    }
   ],
   "source": [
    "data = {'City': ['Chennai', 'Hyderabad', 'Bangalore', 'Delhi', 'Noida']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'City' column to categorical type\n",
    "df['City'] = df['City'].astype('category')\n",
    "\n",
    "# Label encode the 'City' column\n",
    "df['City_LabelEncoded'] = df['City'].cat.codes\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3622da-1fef-478c-aa19-d1852432c019",
   "metadata": {},
   "source": [
    "### Sorting Ordinal Data\n",
    "\n",
    "- Sorting ordinal data involves arranging categories in a meaningful order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "585350d2-9285-47bf-bcf1-c65c389dd87c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Sorting:\n",
      "  Student Grade\n",
      "0    Alex     B\n",
      "1   Billy     C\n",
      "2   Candy     A\n",
      "3   Diana     D\n",
      "4     Eva     B\n",
      "\n",
      "After Sorting:\n",
      "  Student Grade\n",
      "2   Candy     A\n",
      "0    Alex     B\n",
      "4     Eva     B\n",
      "1   Billy     C\n",
      "3   Diana     D\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with an ordinal column\n",
    "data = {'Student': ['Alex', 'Billy', 'Candy', 'Diana', 'Eva'],\n",
    "        'Grade': ['B', 'C', 'A', 'D', 'B']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the logical order of grades\n",
    "grade_order = ['A', 'B', 'C', 'D', 'F']\n",
    "\n",
    "# Convert the 'Grade' column to a categorical type with specified order\n",
    "df['Grade'] = pd.Categorical(df['Grade'], categories=grade_order, ordered=True)\n",
    "\n",
    "print(\"Before Sorting:\")\n",
    "print(df)\n",
    "\n",
    "# Sorting\n",
    "df_sorted = df.sort_values(by='Grade')\n",
    "\n",
    "print(\"\\nAfter Sorting:\")\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5f07d-b557-4049-adf9-8d20011ddc8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multi-indexing\n",
    "\n",
    "- Multi-indexing, also known as hierarchical indexing, allows you to have multiple index levels in a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "645855ed-52de-4cd7-a5ce-cf6af1793ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Value Category\n",
      "Date       Order                 \n",
      "2023-01-01 First      10        A\n",
      "           Second     15        B\n",
      "2023-01-02 First      20        A\n",
      "           Second     25        B\n",
      "2023-01-03 First      30        A\n",
      "           Second     35        B\n"
     ]
    }
   ],
   "source": [
    "data = {'Value': [10, 15, 20, 25, 30, 35],\n",
    "        'Category': ['A', 'B', 'A', 'B', 'A', 'B']}\n",
    "index = pd.MultiIndex.from_tuples([('2023-01-01', 'First'), ('2023-01-01', 'Second'),\n",
    "                                  ('2023-01-02', 'First'), ('2023-01-02', 'Second'),\n",
    "                                  ('2023-01-03', 'First'), ('2023-01-03', 'Second')],\n",
    "                                 names=['Date', 'Order'])\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
